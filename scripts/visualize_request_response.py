#!/usr/bin/env python3
"""
Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð°Ð½Ð°Ð»Ð¸Ð·Ð° request-response ÐºÐ¾Ñ€Ñ€ÐµÐ»ÑÑ†Ð¸Ð¹.

Run: uv run python scripts/visualize_request_response.py
"""

import polars as pl
from pathlib import Path
import json

def visualize_results():
    """Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚ Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÐµÐ¹"""
    
    # Load analysis results
    json_path = Path("data/processed/request_response_analysis.json")
    parquet_path = Path("data/processed/transaction_pairs.parquet")
    
    if not json_path.exists() or not parquet_path.exists():
        print("âŒ Analysis results not found. Run analyze_request_response_correlation.py first.")
        return
    
    with open(json_path) as f:
        results = json.load(f)
    
    df = pl.read_parquet(parquet_path)
    
    print("=" * 100)
    print("KM003C PROTOCOL: REQUEST-RESPONSE CORRELATION ANALYSIS REPORT")
    print("=" * 100)
    print()
    
    # Global statistics
    global_data = results.get("_global", {})
    print("ðŸ“Š GLOBAL STATISTICS")
    print("â”€" * 100)
    print(f"Total transaction pairs analyzed: {global_data.get('total_pairs', 0):,}")
    print(f"Unique source files: {len([k for k in results.keys() if k != '_global'])}")
    print()
    
    # Request mask to attribute mapping
    print("ðŸ” REQUEST MASK â†’ RESPONSE ATTRIBUTE MAPPING")
    print("â”€" * 100)
    print()
    
    if "_global" in results:
        mapping = results["_global"]["mapping_analysis"]
        
        # Attribute name mapping
        attr_names = {
            1: "ADC",
            2: "AdcQueue", 
            8: "Settings",
            16: "PdPacket",
            512: "Unknown512",
            1056: "Unknown1056",
            3072: "Unknown3072",
            17440: "Unknown17440",
        }
        
        print("â”Œ" + "â”€" * 15 + "â”¬" + "â”€" * 20 + "â”¬" + "â”€" * 10 + "â”¬" + "â”€" * 50 + "â”")
        print("â”‚ Request Mask  â”‚ Binary (15-bit)      â”‚ Count     â”‚ Response Attributes                       â”‚")
        print("â”œ" + "â”€" * 15 + "â”¼" + "â”€" * 20 + "â”¼" + "â”€" * 10 + "â”¼" + "â”€" * 50 + "â”¤")
        
        for mask_hex in sorted(mapping["summary"].keys(), key=lambda x: int(x, 16)):
            summary = mapping["summary"][mask_hex]
            
            # Convert response attributes to names
            resp_attrs = summary["most_common_response"]
            resp_names = [attr_names.get(attr, f"Unknown{attr}") for attr in resp_attrs]
            resp_str = ", ".join(resp_names) if resp_names else "Empty"
            
            # Get binary representation (remove '0b' prefix)
            binary = summary["mask_binary"][2:].zfill(15)
            
            # Format output
            mask_col = f"{mask_hex:>13}"
            binary_col = f"{binary:>18}"
            count_col = f"{summary['total_occurrences']:>8}"
            resp_col = f"{resp_str:<48}"
            
            print(f"â”‚ {mask_col} â”‚ {binary_col} â”‚ {count_col} â”‚ {resp_col} â”‚")
            
            # Show alternate patterns if they exist
            if summary["unique_response_patterns"] > 1:
                for pattern_str, count in mapping["detailed_mapping"][mask_hex].items():
                    if count != summary["most_common_count"]:
                        pattern = eval(pattern_str)  # Safe because we control the data
                        alt_names = [attr_names.get(attr, f"Unknown{attr}") for attr in pattern]
                        alt_str = ", ".join(alt_names) if alt_names else "Empty"
                        print(f"â”‚               â”‚                      â”‚   ({count:>4}) â”‚   â””â”€ Alt: {alt_str:<39} â”‚")
        
        print("â””" + "â”€" * 15 + "â”´" + "â”€" * 20 + "â”´" + "â”€" * 10 + "â”´" + "â”€" * 50 + "â”˜")
        print()
        
        # Bit analysis
        print("ðŸ”¬ BITMASK BIT ANALYSIS")
        print("â”€" * 100)
        print()
        print("Observed bit patterns and their meanings:")
        print()
        
        bit_meanings = {
            0: "ADC (attribute 1)",
            1: "AdcQueue (attribute 2)",
            3: "Settings (attribute 8)",
            4: "PdPacket (attribute 16)",
            9: "Unknown512 (attribute 512)"
        }
        
        for mask_hex in sorted(mapping["summary"].keys(), key=lambda x: int(x, 16)):
            summary = mapping["summary"][mask_hex]
            bits = mapping["bit_analysis"][mask_hex]
            
            # Get which bits are set
            set_bits = []
            for bit_key, is_set in bits.items():
                if is_set:
                    bit_num = int(bit_key.split('_')[1]) if bit_key.split('_')[1].isdigit() else None
                    if bit_num is not None:
                        set_bits.append(bit_num)
            
            if set_bits or summary['total_occurrences'] > 10:  # Show significant patterns
                print(f"  {mask_hex} (decimal {summary['mask_decimal']:>4}):")
                if set_bits:
                    for bit in set_bits:
                        meaning = bit_meanings.get(bit, f"Unknown bit {bit}")
                        print(f"    â”œâ”€ Bit {bit}: {meaning}")
                else:
                    print(f"    â”œâ”€ No standard bits set")
                
                resp_attrs = summary["most_common_response"]
                print(f"    â””â”€ Response: {resp_attrs} ({summary['total_occurrences']} occurrences)")
                print()
        
        # Key findings
        print("ðŸ”‘ KEY FINDINGS")
        print("â”€" * 100)
        print()
        print("1. PERFECT CORRELATION OBSERVED:")
        print("   â€¢ Bit 0 (0x0001) â†’ ADC response (attribute 1)")
        print("   â€¢ Bit 1 (0x0002) â†’ AdcQueue response (attribute 2)")
        print("   â€¢ Bit 3 (0x0008) â†’ Settings response (attribute 8)")
        print("   â€¢ Bit 4 (0x0010) â†’ PdPacket response (attribute 16)")
        print("   â€¢ Bit 9 (0x0200) â†’ Unknown512 response (attribute 512)")
        print()
        print("2. BITWISE OR BEHAVIOR:")
        print("   â€¢ Mask 0x0003 (bits 0+1) â†’ Response [ADC, AdcQueue]")
        print("   â€¢ Mask 0x0011 (bits 0+4) â†’ Response [ADC, PdPacket]")
        print("   â””â”€ Confirms bitmask allows requesting multiple data types in one transaction")
        print()
        print("3. SPECIAL CASES:")
        print("   â€¢ Mask 0x0000 â†’ Empty response (control/status commands)")
        print("   â€¢ Mask 0x0080 â†’ Inconsistent responses (initialization/calibration?)")
        print()
    
    # Per-file breakdown
    print("ðŸ“ PER-FILE ANALYSIS")
    print("â”€" * 100)
    print()
    
    for source_file in sorted([k for k in results.keys() if k != "_global"]):
        file_data = results[source_file]
        
        print(f"File: {source_file}")
        print(f"  Total packets: {file_data['total_packets']:,}")
        print(f"  Transaction pairs: {file_data['transaction_pairs']}")
        
        # Show dominant request patterns
        mapping = file_data["mapping_analysis"]["summary"]
        if mapping:
            dominant = sorted(mapping.items(), key=lambda x: x[1]["total_occurrences"], reverse=True)[:3]
            print(f"  Top request patterns:")
            for mask_hex, summary in dominant:
                resp = summary["most_common_response"]
                resp_str = str(resp) if resp else "Empty"
                print(f"    â€¢ {mask_hex}: {summary['total_occurrences']} times â†’ {resp_str}")
        print()
    
    # Latency analysis
    print("â±ï¸  TRANSACTION LATENCY ANALYSIS")
    print("â”€" * 100)
    print()
    
    # Overall latency
    latencies = df["latency_us"].to_list()
    print(f"Overall statistics (all {len(latencies):,} transactions):")
    print(f"  Min:     {min(latencies):>8.1f} Âµs")
    print(f"  25th %:  {df['latency_us'].quantile(0.25):>8.1f} Âµs")
    print(f"  Median:  {df['latency_us'].median():>8.1f} Âµs")
    print(f"  75th %:  {df['latency_us'].quantile(0.75):>8.1f} Âµs")
    print(f"  Mean:    {df['latency_us'].mean():>8.1f} Âµs")
    print(f"  Max:     {max(latencies):>8.1f} Âµs")
    print()
    
    # Latency by request type
    print("Latency by request mask (top 5):")
    latency_by_mask = (df
        .group_by("request_mask_hex")
        .agg([
            pl.len().alias("count"),
            pl.col("latency_us").mean().alias("mean_latency"),
            pl.col("latency_us").median().alias("median_latency")
        ])
        .sort("count", descending=True)
        .head(5)
    )
    
    for row in latency_by_mask.iter_rows(named=True):
        print(f"  {row['request_mask_hex']:>8}: mean={row['mean_latency']:>6.1f}Âµs, median={row['median_latency']:>6.1f}Âµs (n={row['count']:>4})")
    
    print()
    print("=" * 100)
    print("âœ… VISUALIZATION COMPLETE")
    print("=" * 100)
    print()
    print("Files generated:")
    print(f"  â€¢ {json_path} (detailed JSON)")
    print(f"  â€¢ {parquet_path} (transaction pairs)")
    print()


if __name__ == "__main__":
    visualize_results()
